{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CCBDA-HW4-309505031.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgura1n58l2U"
      },
      "source": [
        "# Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vC78lNUw8l2X"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('public.csv')\n",
        "#df[df[\"Exited\"]==0].count()\n",
        "#df.head()\n",
        "#df.corr(method='pearson')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49tP9Yxi8l2Z"
      },
      "source": [
        "# Use Pyspark to view dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_hQzd539QXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3bd95d7-bda6-4cd1-ec8a-32f45e131ec2"
      },
      "source": [
        "!apt-get -y install openjdk-8-jre-headless\n",
        "!pip install pyspark"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-8-jre-headless is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeuTZBcC8l2a"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Churn_Modelling\").getOrCreate()\n",
        "df = spark.read.csv('public.csv',header=True,inferSchema=True)\n",
        "#df.printSchema()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BOpeNNx8l2b"
      },
      "source": [
        "# Do your work here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHZAhn048l2c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from pyspark.sql.functions import col, when, udf\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.ml.feature import RFormula\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, LinearSVC\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.functions import round\n",
        "from sklearn import metrics\n",
        "import numpy as np"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0zWrmD1cns0"
      },
      "source": [
        "clean_df = df.select('CustomerId', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts'\\\n",
        "                     , 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCFOXY3Jvvxs"
      },
      "source": [
        "# assign higher weights to (Exited == 1).\n",
        "balancingRatio = clean_df.filter(col('Exited') == 1).count() / clean_df.count()\n",
        "calculateWeights = udf(lambda x: 1 * balancingRatio if x == 0 else (1 * (1.0 - balancingRatio)), DoubleType())\n",
        "weighted_df = clean_df.withColumn(\"Weight\", calculateWeights(\"Exited\"))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLv6Pvg1eIUd"
      },
      "source": [
        "sI1 = StringIndexer(inputCol=\"Geography\", outputCol=\"GeographyIndex\")\n",
        "en1 = OneHotEncoder(dropLast=False, inputCol=\"GeographyIndex\", outputCol=\"GeographyVec\")\n",
        "sI2 = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
        "en2 = OneHotEncoder(dropLast=False, inputCol=\"GenderIndex\", outputCol=\"GenderVec\")\n",
        "\n",
        "encoded_final_df = Pipeline(stages=[sI1, en1, sI2, en2]).fit(weighted_df).transform(weighted_df)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfqJAEbGfq7D"
      },
      "source": [
        "trainingFraction = 0.8\n",
        "testingFraction = (1-trainingFraction)\n",
        "seed = 1234\n",
        "\n",
        "train_data_df, test_data_df = encoded_final_df.randomSplit([trainingFraction, testingFraction], seed=seed)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rebRnMIlfz6U"
      },
      "source": [
        "#logReg = LogisticRegression(labelCol='Exited', weightCol='Weight')\n",
        "rf = RandomForestClassifier(labelCol='Exited', weightCol='Weight', numTrees=10)\n",
        "#lsvc = LinearSVC(maxIter=10, regParam=0.1, weightCol='Weight')\n",
        "\n",
        "classFormula = RFormula(formula=\"Exited ~ CreditScore + GeographyVec + GenderVec + Age + Tenure + Balance + NumOfProducts + HasCrCard + IsActiveMember + EstimatedSalary\")\n",
        "model = Pipeline(stages=[classFormula, rf]).fit(train_data_df)\n",
        "trainingSummary = model.stages[-1].summary\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maINJMntpePO",
        "outputId": "d8281923-a6fb-4b26-e251-4b46a35c8bf6"
      },
      "source": [
        "accuracy = trainingSummary.accuracy\n",
        "recall = trainingSummary.recallByLabel\n",
        "print(f\"accuracy: {accuracy}, recall: {recall}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7796900906285764, recall: [0.8257114818449484, 0.7339864355689518]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rh3P5mDqfJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f944b87e-10b0-4c01-b20a-0d4d375c4cae"
      },
      "source": [
        "predictions = model.transform(test_data_df)\n",
        "predictionAndLabels = predictions.select(\"label\", \"prediction\").rdd\n",
        "metric = BinaryClassificationMetrics(predictionAndLabels)\n",
        "print(\"Area under ROC = %s\" % metric.areaUnderROC)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under ROC = 0.708796556900272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZmeVq5qbFc",
        "outputId": "0eb0708d-f35e-4c80-d7c4-1155888e9cd9"
      },
      "source": [
        "y_true =  np.array(predictions.select(\"label\").collect())\n",
        "y_pred = np.array(predictions.select(\"prediction\").collect())\n",
        "metrics.f1_score(y_true, y_pred, average='micro')  "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7978453738910013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRZqJ5Qv8l2c"
      },
      "source": [
        "# Evaluation Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVDCMc5M8l2c"
      },
      "source": [
        "## Load private dataset, the same structure as public dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niFwLliW8l2d"
      },
      "source": [
        "df_private = spark.read.csv('public.csv',header=True,inferSchema=True)  # TA takes public dataset as example"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baD_2ISp8l2d"
      },
      "source": [
        "## Do prediction with your PySpark model here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaEkGxGb8l2e"
      },
      "source": [
        "encoded_df_private = Pipeline(stages=[sI1, en1, sI2, en2]).fit(df_private).transform(df_private)\n",
        "pred = model.transform(encoded_df_private)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fXGht_j8l2e"
      },
      "source": [
        "## Print Your result as the following type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpb5_Edv8l2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d55167-bd17-41a8-a387-6e83eab4fb7b"
      },
      "source": [
        "pred.select('CustomerId','prediction').show(5)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+\n",
            "|CustomerId|prediction|\n",
            "+----------+----------+\n",
            "|  15565701|       0.0|\n",
            "|  15565706|       0.0|\n",
            "|  15565796|       1.0|\n",
            "|  15565806|       0.0|\n",
            "|  15565878|       0.0|\n",
            "+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWSLXdbR8l2e"
      },
      "source": [
        "## TA will use the following function to get your prediction result (f-1 score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyFHE3Ln8l2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4029802-6dff-48ab-acfd-2265a2dd59fe"
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "data_array =  np.array(df_private.select(\"Exited\").collect())\n",
        "data_pred = np.array(pred.select(\"prediction\").collect())\n",
        "\n",
        "metrics.f1_score(data_array, data_pred, average='micro')  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}